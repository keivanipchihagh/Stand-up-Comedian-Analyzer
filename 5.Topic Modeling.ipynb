{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attended-command",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "shared-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-graphic",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hourly-catalog",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lousic C.K.</th>\n",
       "      <th>Dave Chappelle</th>\n",
       "      <th>Ricky Gervais</th>\n",
       "      <th>Bo Burham</th>\n",
       "      <th>Bill Burr</th>\n",
       "      <th>Jim Jefferies</th>\n",
       "      <th>John Mulaney</th>\n",
       "      <th>Hasan Minhaj</th>\n",
       "      <th>Ali Wong</th>\n",
       "      <th>Anthony Jeselnik</th>\n",
       "      <th>Mike Birbiglia</th>\n",
       "      <th>Joe Rogan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaaaah</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaahhhhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaauuugghhhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaahhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaah</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zillion</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>éclair</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5766 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Lousic C.K.  Dave Chappelle  Ricky Gervais  Bo Burham  \\\n",
       "aaaaah                      0               0              0          0   \n",
       "aaaaahhhhhhh                0               0              0          1   \n",
       "aaaaauuugghhhhhh            0               0              0          1   \n",
       "aaaahhhhh                   0               0              0          1   \n",
       "aaah                        0               1              0          0   \n",
       "...                       ...             ...            ...        ...   \n",
       "zillion                     0               0              0          0   \n",
       "zombie                      0               0              0          0   \n",
       "zone                        0               0              0          0   \n",
       "zoo                         0               0              1          0   \n",
       "éclair                      0               0              0          0   \n",
       "\n",
       "                  Bill Burr  Jim Jefferies  John Mulaney  Hasan Minhaj  \\\n",
       "aaaaah                    1              0             0             0   \n",
       "aaaaahhhhhhh              0              0             0             0   \n",
       "aaaaauuugghhhhhh          0              0             0             0   \n",
       "aaaahhhhh                 0              0             0             0   \n",
       "aaah                      0              0             0             0   \n",
       "...                     ...            ...           ...           ...   \n",
       "zillion                   1              0             0             0   \n",
       "zombie                    2              0             0             0   \n",
       "zone                      1              0             0             0   \n",
       "zoo                       0              0             0             0   \n",
       "éclair                    0              0             1             0   \n",
       "\n",
       "                  Ali Wong  Anthony Jeselnik  Mike Birbiglia  Joe Rogan  \n",
       "aaaaah                   0                 0               0          0  \n",
       "aaaaahhhhhhh             0                 0               0          0  \n",
       "aaaaauuugghhhhhh         0                 0               0          0  \n",
       "aaaahhhhh                0                 0               0          0  \n",
       "aaah                     0                 0               0          0  \n",
       "...                    ...               ...             ...        ...  \n",
       "zillion                  0                 0               0          0  \n",
       "zombie                   1                 0               0          0  \n",
       "zone                     0                 0               0          0  \n",
       "zoo                      0                 0               0          0  \n",
       "éclair                   0                 0               0          0  \n",
       "\n",
       "[5766 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vec_df = pd.read_csv('saves/3.stopwords_vectorized_df.csv', index_col = 0).transpose()\n",
    "vec_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-geology",
   "metadata": {},
   "source": [
    "## Overall topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "daily-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_counts = scipy.sparse.csr_matrix(vec_df)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "shaped-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "vectorizer = pickle.load(open(\"saves/3.vectorizer.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "practical-bracelet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"dad\" + 0.006*\"tell\" + 0.006*\"ve\" + 0.006*\"love\" + 0.004*\"day\" + 0.004*\"yeah\" + 0.004*\"really\" + 0.004*\"school\" + 0.004*\"mean\" + 0.004*\"joke\"'),\n",
       " (1,\n",
       "  '0.009*\"shit\" + 0.008*\"yeah\" + 0.007*\"man\" + 0.007*\"ve\" + 0.006*\"kid\" + 0.006*\"day\" + 0.006*\"woman\" + 0.006*\"little\" + 0.005*\"cause\" + 0.005*\"life\"')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus = corpus, id2word = id2word, num_topics = 2, passes = 10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "excess-sharp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"ve\" + 0.009*\"joke\" + 0.009*\"yeah\" + 0.007*\"day\" + 0.007*\"love\" + 0.006*\"little\" + 0.005*\"tell\" + 0.005*\"year\" + 0.005*\"woman\" + 0.005*\"shit\"'),\n",
       " (1,\n",
       "  '0.009*\"shit\" + 0.007*\"man\" + 0.007*\"kid\" + 0.006*\"yeah\" + 0.006*\"ve\" + 0.006*\"cause\" + 0.006*\"life\" + 0.006*\"day\" + 0.006*\"really\" + 0.005*\"tell\"'),\n",
       " (2,\n",
       "  '0.001*\"yeah\" + 0.001*\"ve\" + 0.000*\"man\" + 0.000*\"kid\" + 0.000*\"tell\" + 0.000*\"cause\" + 0.000*\"life\" + 0.000*\"love\" + 0.000*\"shit\" + 0.000*\"day\"')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus = corpus, id2word = id2word, num_topics = 3, passes = 10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "pursuant-insertion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"man\" + 0.009*\"shit\" + 0.008*\"kid\" + 0.008*\"cause\" + 0.008*\"life\" + 0.007*\"ve\" + 0.007*\"woman\" + 0.006*\"really\" + 0.006*\"day\" + 0.005*\"girl\"'),\n",
       " (1,\n",
       "  '0.011*\"shit\" + 0.010*\"man\" + 0.009*\"ahah\" + 0.008*\"black\" + 0.007*\"woman\" + 0.006*\"rape\" + 0.005*\"ve\" + 0.005*\"walk\" + 0.005*\"lot\" + 0.005*\"gay\"'),\n",
       " (2,\n",
       "  '0.009*\"yeah\" + 0.008*\"ve\" + 0.007*\"day\" + 0.006*\"kid\" + 0.006*\"tell\" + 0.006*\"love\" + 0.006*\"dad\" + 0.005*\"year\" + 0.005*\"joke\" + 0.005*\"shit\"'),\n",
       " (3,\n",
       "  '0.008*\"love\" + 0.007*\"shit\" + 0.006*\"yeah\" + 0.006*\"bo\" + 0.006*\"man\" + 0.006*\"ok\" + 0.006*\"stuff\" + 0.005*\"ve\" + 0.005*\"woman\" + 0.005*\"repeat\"')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus = corpus, id2word = id2word, num_topics = 4, passes = 10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "spoken-physiology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.012*\"life\" + 0.010*\"tit\" + 0.008*\"cause\" + 0.008*\"kid\" + 0.008*\"shit\" + 0.008*\"old\" + 0.007*\"happen\" + 0.007*\"murder\" + 0.006*\"woman\" + 0.006*\"mean\"'),\n",
       " (1,\n",
       "  '0.011*\"ve\" + 0.009*\"dad\" + 0.007*\"love\" + 0.007*\"day\" + 0.007*\"man\" + 0.006*\"girl\" + 0.006*\"gun\" + 0.006*\"kid\" + 0.005*\"tell\" + 0.005*\"life\"'),\n",
       " (2,\n",
       "  '0.013*\"shit\" + 0.008*\"yeah\" + 0.008*\"man\" + 0.007*\"kid\" + 0.007*\"tell\" + 0.006*\"woman\" + 0.006*\"dude\" + 0.006*\"day\" + 0.005*\"ve\" + 0.005*\"lot\"'),\n",
       " (3,\n",
       "  '0.008*\"love\" + 0.007*\"little\" + 0.006*\"ve\" + 0.006*\"walk\" + 0.006*\"yeah\" + 0.006*\"bo\" + 0.005*\"clinton\" + 0.005*\"old\" + 0.005*\"way\" + 0.005*\"stuff\"'),\n",
       " (4,\n",
       "  '0.010*\"yeah\" + 0.009*\"ve\" + 0.006*\"mean\" + 0.006*\"cause\" + 0.006*\"year\" + 0.006*\"joke\" + 0.006*\"day\" + 0.005*\"really\" + 0.005*\"little\" + 0.005*\"jenny\"')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus = corpus, id2word = id2word, num_topics = 5, passes = 10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-oriental",
   "metadata": {},
   "source": [
    "## Nouns topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "incorrect-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-aluminum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-cinema",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-andrews",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
